<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/modern-normalize/modern-normalize.min.css">
    <link rel="stylesheet" href="/JLR2026/css/base.css?ts=202611131128"><link rel="stylesheet" href="/JLR2026/css/program.css"><link rel="icon" href="/JLR2026/img/icon.svg" type="image/svg+xml">

    <title>JLR2026 プログラム | NLP2026 Workshop on Japanese Language Resources</title>

    <meta property="og:title" content="JLR2026 プログラム" />
    <meta property="og:site_name" content="Japanese Language Resources Workshop" />
    <meta property="og:description" content="言語処理学会第32回年次大会 併設ワークショップ JLR2026 - プログラム" />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://jedworkshop.github.io/JLR2026/img/icon.png">
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="600" />
    <meta property="og:image:height" content="600" />
    <meta property="og:image:alt" content="JLR" />
    <meta name="twitter:card" content="summary" />
</head>
<body>
    <header><a href="/JLR2026/">NLP2026 Workshop on Japanese Language Resources (JLR2026)</a></header>
    <main>
        <div class="subheading">
            言語処理学会第32回年次大会 併設ワークショップ JLR2026 - プログラム
        </div>
        
<h1>JLR2026 プログラム</h1>


<p>2026年3月13日(金)<br/>ライトキューブ宇都宮＋オンライン中継のハイブリッド開催</p>

<div class="twitter_info">
<div class="accoutn">公式アカウント<a href="https://twitter.com/jedws" target="_blank" rel="noreferrer">@jedws</a></div>
</div>

<div id="program_table">


  <div class="flex-row">
    <div class="program_time flex-item">10:00-10:05</div>
    <div class="flex-item">オープニング </div>
  </div>

  <div class="flex-row">
    <div class="program_time flex-item">10:05-11:45</div>
    <div class="flex-item"><a href="#午前＜１＞">午前＜１＞ : 一般発表 4件 ライトニングトーク</a></div>
  </div>

  <div class="flex-row">
    <div class="program_time flex-item">11:45-13:00</div>
    <div class="flex-item">昼休憩 </div>
  </div>

  <div class="flex-row">
    <div class="program_time flex-item">13:00-14:35</div>
    <div class="flex-item"><a href="#午後＜１＞">午後＜１＞ : 一般発表 4件 ライトニングトーク</a></div>
  </div>

  <div class="flex-row">
    <div class="program_time flex-item">14:45-15:45</div>
    <div class="flex-item"><a href="#午後＜２＞">午後＜２＞ : 一般発表 2件 ライトニングトーク</a></div>
  </div>

  <div class="flex-row">
    <div class="program_time flex-item">15:45-16:00</div>
    <div class="flex-item">総合討論・クロージング </div>
  </div>


</div>



<div class="program_legend">
  <div>
    <div class="icons">🎤 一般発表 &nbsp; ⚡ ライトニングトーク &nbsp; 💻 オンライン発表</div>
    <div class="caveat">(発表時間は当日の進行状況により前後することがあります)</div>
  </div>
  <div>
    <div class="btn_abstract_all" data-target=".abstract" data-action="open">全ての概要を開く</div>
  </div>
</div>


  <div class="session" id="午前＜１＞">
    <h2>午前＜１＞
    <a class="header-anchor" href="#午前＜１＞">
        <span class="heading-anchor" aria-hidden="true">¶</span>
    </a>
    </br><small>10:05-11:45</small>&nbsp; <small>座長: 河原 大輔 (早稲田大)</small></h2><div class="talk_list"><div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">10:05-10:25</div>
                        <div class="title">独自日本語Webコーパス構築のための巡回クロール基盤構築</div>
                        <div class="presenter">石原 慧人 (SB Intuitions)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_a-1">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_a-1">
                        日本語大規模言語モデルの事前学習には大量の日本語テキストが必要である。しかし、Webから収集可能な日本語テキストの総量は英語と比較して限られている上、Common Crawlなどの既存Webアーカイブは英語中心に収集されているため、日本語ページの網羅性には課題がある。こうした制約の中で高品質な日本語コーパスを構築するには、限られた計算資源で効率的に日本語テキストを収集する手法が求められる。本発表では、日本語Webコーパス構築のためのクローリング基盤の設計上の工夫とその運用から得られた知見を報告する。具体的には、日本語ドメインを対象とした優先度付きURL選択と、robots.txtへの準拠などクローリングを行う際に求められるポライトネスに配慮した大規模並列収集により、効率的な日本語テキスト収集を実現した。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">10:25-10:45</div>
                        <div class="title">番組映像を活用したマルチモーダルデータセット開発の取り組み</div>
                        <div class="presenter">岡田 拓也, 遠藤 伶, 中村 純也, 田中 大, 衣川 和尭, 美野 秀弥, 宮﨑 太郎, 河合 吉彦 (NHK)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_a-2">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_a-2">
                        放送ドメインに特化した制作支援タスクの学習には高品質な大規模言語資源の整備が必要である一方、番組映像を対象としたマルチモーダルデータセットは公開例が少なく、特に映像・音声・字幕を統合した日本語マルチモーダル資源はほとんど整備されていない。そこで本研究では、放送済みの15分以下の番組映像（総計約2.3万時間）を用いて、マルチモーダル大規模言語モデル（MLLM）の制作支援能力の強化を目的とする指示学習データの開発に取り組んだ。さらに、MLLMの総合的な映像理解能力を評価するため、日本のテレビ番組を模擬した評価用映像を新たに制作し、それらに対して人手でアノテーションを付与したVQAベンチマークを試作した。本発表では、指示学習タスク設計、データセット作成パイプライン、VQAベンチマークといった開発内容について紹介するとともに現時点で得られた知見を報告する。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">10:45-11:15</div>
                        <div class="title">BizDocVQA：根拠領域のアノテーションによる説明可能なビジネス帳票理解の実現と評価</div>
                        <div class="presenter">久保 隆宏 (アマゾンウェブサービスジャパン)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_a-3">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_a-3">
                        文書画像に対する質問回答（DocVQA）は、マルチモーダルLLMの登場により精度が飛躍的に向上したがビジネス応用に不可欠な「視覚的証拠の特定能力」の評価は不十分である。従来研究はPDFの論文など整形された文書を中心に評価しており、ノイズやレイアウト依存性の高い実社会の帳票での検証は未知数だった。本発表では、実世界のレシートを対象に、回答と共に根拠となる矩形領域をアノテーションした「BizDocVQA」データセットを提案する。最新モデルでの性能計測を行った結果、高い回答精度と根拠箇所の特定精度の間に乖離があることが判明した。本発表では DocVQA 研究動向を概観し、本データセットで明らかになった「視覚的根拠付き回答」の課題と、多言語展開を含む今後の展望について議論する。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">11:15-11:35</div>
                        <div class="title">論文に基づく歴史学知識資源の公開に向けたデータセット記述の精緻化</div>
                        <div class="presenter">亀田 尭宙 (人間文化研究機構)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_a-4">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_a-4">
                        人文学のデータ公開を促進する立場にいる著者が、とりわけ歴史学の「読み解き」に関わる知識資源を、論文を主な情報源として構築した際に直面した困難と対応策を報告する。オープンアクセス可能な論文が多くなく、また著作権がオープンになっていない現状では、論文本文をそのままデータセット化することは難しい。しかし、著作権が切れている史料に基づく事実（例：史料名・読み）は公開可能なはずである。そこで、見解が分かれる論点（例：校訂の著作物性）も含め、データセット側に根拠と立場を明示する実践を紹介する。さらに、PD資料に著作権表示を要求する等の“非著作権的要請”が著作権に押し付けられる一方、著作権以外の権利・配慮事項が軽視されがちな現状がある。これらをAI構築などに用いる利用者が適切に扱えるよう、CONTRIBUTORS.md や NOTICE.md 等に切り分け、引用や権利留保の導線を整備する。
                    </div>
                <div class="talk lt">
                    <div class="icon lt"></div>
                    <div class="info">
                        <div class="time">11:35-11:45</div>
                        <div class="title">日本語の科学設問集の複数評価者による難易度付けと評価者間不一致の分析</div>
                        <div class="presenter">江原 遥 (東京学芸大)  💻 </div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_a-5">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_a-5">
                        LLM評価で用いられるMMLUの日本語版JMMLUには英語圏で高校レベルとされるが日本での難易度が不明な科学（物理・化学・生物）設問がある。これに対し、日本の学習指導要領に基づく4段階難易度で各問2名が独立に付与したデータセットを作成した。難易度に加えて評価者間不一致の分析や判断が割れる設問の特徴を分析でき、LLMの科学・教育応用において日本語に限らず希少かつ有用な資源と思われるので報告する。
                    </div>
                </div></div>



  <div class="session" id="午後＜１＞">
    <h2>午後＜１＞
    <a class="header-anchor" href="#午後＜１＞">
        <span class="heading-anchor" aria-hidden="true">¶</span>
    </a>
    </br><small>13:00-14:35</small>&nbsp; <small>座長: 柴田 知秀 (SB Intuitions)</small></h2><div class="talk_list"><div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">13:00-13:20</div>
                        <div class="title">軽量な日本語報酬モデル ca-reward-3b-ja の構築と公開</div>
                        <div class="presenter">三橋亮太 (サイバーエージェント)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_b-1">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_b-1">
                        本発表では軽量な日本語報酬モデルca-reward-3b-jaの開発と公開について報告する。報酬モデルとは、人間の選好を学習しLLMの出力の好ましさをスコア化するモデルである。RLHFの代理報酬、Best-of-Nによる最良応答の選択、リランキングによる品質の並び替え等に活用できる。事業応用の観点でも、大量の生成結果を即座に評価できる意義は大きく、非定型タスクでのモデル改善やエージェント応用における強化学習への展開が期待される。しかし日本語に特化した報酬モデルは不足している。本モデルは3Bの実用的なサイズで推論コストを抑えつつ、日本語ベースモデルと日本語合成データで日本語特化の学習を行った。学習データは社内で構築し、LLM-as-a-Judgeによる疑似選好ラベルを付与した。人手の選好ラベルが付与されたベンチマークで、大型モデルに迫る分類性能を達成した。モデルはApache-2.0で公開する。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">13:20-13:40</div>
                        <div class="title">日本語大規模言語モデルの推論能力向上のための強化学習データセット構築</div>
                        <div class="presenter">太田 晋, 片山 結太 (東京科学大), 水木 栄 (東京科学大・産総研), 岡崎 直観 (東京科学大・産総研・NII LLMC)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_b-2">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_b-2">
                        本研究では，日本語大規模言語モデル（LLM）の推論能力向上を目的として，数学・科学・コード生成タスクを対象とする日本語設問・解答データセットを構築した．本データセットは，英語の指示学習データセット s1 を基に設問を邦訳し，解答付与および解答可能性アノテーションを施すことで，検証可能な報酬を用いた強化学習（Reinforcement Learning with Verifiable Rewards; RLVR）に適した日本語設問・解答ペアを整備した．邦訳には gpt-oss-120b を用い，GEMBA MQM 翻訳品質スコアに基づく棄却サンプリングによって高品質な訳文を選択した．さらに英語版および日本語版データセットを用いて強化学習と包括的評価を実施した結果，本データセットが日本語LLMの推論性能向上に有効であることを確認した．
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">13:40-14:05</div>
                        <div class="title">金融業に特化した生成AIモデルのインストラクションデータ開発プロセス</div>
                        <div class="presenter">佐藤 奈穂子 (リコー)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_b-3">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_b-3">
                        汎用型生成AIの性能が急速に進化し、ビジネスの場にその活用が広がってきたが、実務現場では、多くの業務が属人化しており、業界特有の用語やルールを反映した応用が難しく、導入の障壁となっている。こういった背景から、特定の業界やユースケースに特化したAIモデル「Vertical AI」が注目され、今後も成長、市場規模の拡大が予測されている。　特に金融業界では、業務効率化の取り組みで生成AI導入が加速しているが、不正検出、規制遵守、膨大な情報に基づく信用スコアリングといったユースケースにおいて業務特化ニーズが顕著である。弊社はそれに応えるべく、昨年10月にオンプレミス環境で導入可能で高精度な応答を実現した金融業務特化型LLMを開発、公開した。　本発表では、このモデル開発に向け、業界特有のユースケースに即した表現や知識を学習させるための高品質なインストラクションデータの構築プロセスについて紹介する。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">14:05-14:25</div>
                        <div class="title">語彙を起点とした完全合成によるドメイン特化指示データセットの構築と金融分野での実証</div>
                        <div class="presenter">大河内 悠磨 (NRI), Fabio Milentiansen Sim (NRIインドネシア), 岡田 智靖 (NRI)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_b-4">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_b-4">
                        特定ドメインへのLLM適応には、従来専門文献の収集や人手によるデータ作成が必要不可欠であった。本発表では、既存のテキスト資源に依存せず、ドメイン固有のトピックワードのみを入力とし、LLMによる合成データのみを用いて高品質な指示データセットを構築する汎用的手法を提案する。 本手法は、語彙を起点とした多様な質問生成、指示の改変、思考過程（Chain-of-Thought）を含むマルチターン対話の生成、品質評価を完全自動化するものである。実証として本手法を金融分野に適用し、約95億トークンのデータセットを構築した結果、学習済みモデルが金融ベンチマークにおいて公式モデルを上回る性能を確認した。本手法は金融分野に限らずあらゆる分野へ即座に展開可能であり、言語資源構築におけるコストと手間の制約を打破する新たなアプローチを提示する。 
                    </div>
                <div class="talk lt">
                    <div class="icon lt"></div>
                    <div class="info">
                        <div class="time">14:25-14:35</div>
                        <div class="title">Deep Research結果に対する細粒度引用と矛盾のアノテーション</div>
                        <div class="presenter">松田 耕史, 福地 成彦, 上之薗 有夏, 吉田 奈央 (SB Intuitions)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_b-5">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_b-5">
                        Deep Researchの結果に根拠ドキュメントを引用付与することは、情報の信頼性を高め、ユーザーの確認コストを下げるなどUI/UX改善に直結する。本研究では単なる紐付けに留まらず、回答の各文がドキュメント内のどのパッセージに基づいているか、あるいは矛盾しているかを特定する細粒度のアノテーションを実施した。その設計指針やアノテーター間一致率、議論となった判断基準について詳細を報告する。
                    </div>
                </div></div>



  <div class="session" id="午後＜２＞">
    <h2>午後＜２＞
    <a class="header-anchor" href="#午後＜２＞">
        <span class="heading-anchor" aria-hidden="true">¶</span>
    </a>
    </br><small>14:45-15:45</small>&nbsp; <small>座長: 松田 寛 (Megagon Labs)</small></h2><div class="talk_list"><div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">14:45-15:10</div>
                        <div class="title">日本語インストラクションデータの多様化に向けた高品質な人手データを起点とする合成手法の検討</div>
                        <div class="presenter">宮里 龍平 (電気通信大), 中山 功太 (NII LLMC), 関根 聡 (いちから)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_c-1">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_c-1">
                        本発表では、高品質な日本語LLMの構築に不可欠なインストラクションデータの拡充に向けた、多様なデータ合成の取り組みについて報告する。 人手で丁寧に作成された「いちから」データセットは高品質である一方、作成コストが高く、継続的な拡張には限界がある。また、既存の合成手法では、生成を繰り返す中で指示文が冗長かつ不自然になる課題があった。我々はこれらの課題を解決するため、既存の手法を改良し、より自然で多様な合成を可能にする手法を考案した。具体的には、「条件追加」「具体化」「多様化」といった複数の合成方針をランダムに適用するとともに、人間が既存の指示から着想を得て新たな指示を作成する思考プロセスをプロンプトに統合した。 また、特に指示追従性能の向上に焦点を当て、制約条件の変更や書き換えによる多様なタスクの合成にも取り組んでいる。本報告では、これら手法と、自然な日本語指示文の合成に向けた知見について共有する。
                    </div>
                <div class="talk normal">
                    <div class="icon normal"></div>
                    <div class="info">
                        <div class="time">15:10-15:35</div>
                        <div class="title">人間-LLM間のインタラクション分析に向けたコーパス構築のための談話行為アノテーション設計</div>
                        <div class="presenter">永井 宥之, 伊藤 和浩 (NAIST), 山崎 由佳, 白石 暖哉 (京都大学), 若宮翔子, 荒牧英治 (NAIST)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_c-2">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_c-2">
                        現代は，人間と大規模言語モデル (Large Language Model: LLM) が日常的にコミュニケーションをとる時代である．LLMの発話や応答は極めて自然である一方，それらは特定の意図や信念に基づかないため，人間どうしや従来のチャットボットとのやりとりとは異なるインタラクションが生じうる．具体的には，人間どうしでは有効であったコミュニケーション戦略がLLMに対しては機能しない可能性がある一方，LLM側から人間に働きかける際にも，人間どうしの場合とは異なる戦略が有効となることも予想される．しかし，人間-LLM間の談話行為を体系的に捉えるためのアノテーション仕様やコーパスは発展途上である．本研究は，複数のLLMエージェントと人間によるチャットデータを用い，既存の談話行為タグを拡張したアノテーション仕様の開発を目的とする．本発表では，進行中のアノテーション設計の検討過程と課題を報告する．
                    </div>
                <div class="talk lt">
                    <div class="icon lt"></div>
                    <div class="info">
                        <div class="time">15:35-15:45</div>
                        <div class="title">ユーザの個人特性を含む破綻・修復発話文の収集</div>
                        <div class="presenter">坪倉 和哉, 入部 百合絵 (愛知県立大), 北岡 教英 (豊橋技科大)</div>
                    </div>
                    
                        <div class="btn_abstract" data-target=".abstract.talk_c-3">概要</div>
                    

                    <div class="btn_material disabled">資料</div>

                </div>
                
                    <div class="abstract talk_c-3">
                        近年のLLMの発展により対話システムの応答精度は大きく向上しているが，ハルシネーションや自己矛盾といった対話破綻は未だに避けられない課題として残されている．このため，対話破綻が生じた際に対話の流れを適切に修復する機構が必要である．しかし，システムがどのように自身の破綻を認識し，どのように修復すべきかについての体系的な知見は十分に確立されていない．本発表では，この問題に取り組むために，クラウドワーカーから収集した対話破綻を修復するためのコーパスを紹介する．
                    </div>
                </div></div>




<p><a href="../">トップに戻る</a><p>
    </main>
    <footer><a href="https://github.com/jedworkshop/">Copyright &copy; Japanese Language Resource Workshop. All rights reserved.</a></footer><script src="/JLR2026/js/collapsible.js"></script></body>
</html>